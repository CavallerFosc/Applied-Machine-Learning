{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Different Packages Required\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pinkman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We import nltk for using natural language processing techniques\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this section, we read the data from \n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip(downloaded and \n",
    "# unzipped) and label it accordingly.\n",
    "\n",
    "\n",
    "messages=pd.read_csv('SMSSpamCollection', sep='\\t', names= [\"label\",\"sms\"])\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                     sms\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refining the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this section, we drop the duplicate messages\n",
    "\n",
    "messages.drop_duplicates(subset='sms', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5169</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh sorry leh... I din c ur msg. Not sad alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                                sms\n",
       "count   5169                                               5169\n",
       "unique     2                                               5169\n",
       "top      ham  Eh sorry leh... I din c ur msg. Not sad alread...\n",
       "freq    4516                                                  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these are redundant, just to check the messages\n",
    "messages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label   sms\n",
       "0   ham  4516\n",
       "1  spam   653"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function at first tokenizes the sentences into words, then removes all the punctuations and the stopwords.\n",
    "# Then it does stemming e.g. \"go\", \"going\", \"goes\" all these words are replaced with its root word \"go\".\n",
    "\n",
    "def refinement(text):\n",
    "    token = TweetTokenizer()\n",
    "    wordsandpuncts = token.tokenize(text)\n",
    "    puncts = [\"'\", \"!\",\"?\",\",\",\".\",\"@\", \"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"<\",\">\",\"/\",\";\",\":\",\"|\"]\n",
    "    words = [x for x in wordsandpuncts if x not in puncts]\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    start_words = [w for w in words if not w in stop_words]\n",
    "    stemmer = PorterStemmer() \n",
    "    clean_words=[stemmer.stem(word) for word in start_words]                 \n",
    "    \n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazi, .., avail, bugi, n,...\n",
       "1               [Ok, lar, ..., joke, wif, u, oni, ...]\n",
       "2    [free, entri, 2, wkli, comp, win, FA, cup, fin...\n",
       "3    [U, dun, say, earli, hor, ..., U, c, alreadi, ...\n",
       "4      [nah, I, think, goe, usf, live, around, though]\n",
       "Name: sms, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just for checking how does the function work?\n",
    "messages['sms'].apply(refinement).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = messages['sms']\n",
    "y = messages['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#print(\"Shape of X is {}\".format(X.shape))\n",
    "#print(\"Shape of X_train is {} and shape of y_train is {}\".format(X_train.shape, y_train.shape))\n",
    "#print(\"Shape of X_test is {} and shape of y_test is {}\".format(X_test.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Models with 3 Classifiers: NaiveBayes, SVM, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the pipeline for our three classifiers:\n",
    "# 1. Naive-Bayes : This classifier check if certain word or a certain set of words appearing in a message\n",
    "#    to declare it as spam or ham. Some words have probabilities of appearing in spam and legitimate mail.\n",
    "#    It learns about these probabilities(it also considers the frequency of the words appearing).\n",
    "#    from the training batch. Then, given a message from the test set or the user, it checks the set of words \n",
    "#    appearing in the message and using Bayes theorem count the probability of the message being spam or ham.\n",
    "#\n",
    "# 2. SVM : SVM or Support Vector Machine checks the training data and tries to find a separating hyperplane\n",
    "#          between spams(negative points) and hams(positive points) which maximizes the distance of the plane\n",
    "#          from both the set of points.\n",
    "# \n",
    "# 3. Logistic Regression: Logistic Regression model indicates spam messages as 0 and ham messages as 1. It \n",
    "#                         measures the relationship between the categorical dependent variable and one or more \n",
    "#                         independent variables by estimating probabilities using a logistic function. So, from\n",
    "#                         the training set it tries to produce the logistic or the sigmoid function, that helps\n",
    "#                         determine if some messages from the test set is spam or ham, according to its logistic\n",
    "#                         function value is 0 or 1.\n",
    "#\n",
    "# We do these classifications using pipeline in three steps:\n",
    "# 1. First take the training set and create a bag of words calling our \"refinement\" function as an analyzer and\n",
    "#    convert the collection of text documents to a matrix of token counts using \"CountVectorizer\".\n",
    "# 2. Then, we produce the tf-idf vector from them.\n",
    "# 3. Then we use the desired classifier.\n",
    "\n",
    "NB = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=refinement)),\n",
    "    ('tfidf',TfidfTransformer()), \n",
    "    ('classifier',MultinomialNB())\n",
    "])\n",
    "\n",
    "SVM = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=refinement)),\n",
    "    ('tfidf',TfidfTransformer()), \n",
    "    ('classifier',LinearSVC())\n",
    "])\n",
    "\n",
    "LR = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=refinement)),\n",
    "    ('tfidf',TfidfTransformer()), \n",
    "    ('classifier',LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This produces 5-fold cross validation\n",
    "def cross_val(i):\n",
    "    print(\"The cross validation scores are: {}\".format(cross_val_score(i, X=X_train, y=y_train, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit training data to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit and train the data in the pipeline\n",
    "def fitting(i):\n",
    "    i.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Evauations on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we use the model on the test data\n",
    "def final_result(i):\n",
    "    y_test_predicted = i.predict(X_test)\n",
    "\n",
    "#This produces the accuracy score\n",
    "    print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "    print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted, normalize=False)))\n",
    "    print pd.DataFrame(confusion_matrix(y_test, y_test_predicted), \n",
    "                 index={'true ham', 'true spam'}, \n",
    "                 columns={'pred ham', 'pred spam'})\n",
    "\n",
    "#This produces the precision and recall on the test data\n",
    "    print(\"The classification report is the following:\")\n",
    "    print(classification_report(y_test,y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter choice: 2\n",
      "The classifier used here is SVM.\n",
      "The cross validation scores are: [0.98840206 0.98195876 0.98064516 0.99225806 0.97674419]\n",
      "The fraction of correctly classified samples is 0.986078886311\n",
      "The number of correctly classified samples is 1275\n",
      "           pred spam  pred ham\n",
      "true spam       1123         1\n",
      "true ham          17       152\n",
      "The classification report is the following:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      1.00      0.99      1124\n",
      "       spam       0.99      0.90      0.94       169\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we ask for the user input for which classifier they want to use and print the cross-validation score and\n",
    "# also the final evaluations on the test data. This also produces the classification report, which contains\n",
    "# precision and recall\n",
    "def classifier(i):\n",
    "    if i==NB:\n",
    "        print(\"The classifier used here is Naive-Bayes.\")\n",
    "    elif i== SVM:\n",
    "        print(\"The classifier used here is SVM.\")\n",
    "    elif i== LR:\n",
    "        print(\"The classifier used here is Logistic Regression.\")\n",
    "    cross_val(i)\n",
    "    fitting (i)\n",
    "    final_result(i)\n",
    "note= '''This is the code for spam filter. We have used three classifier. Choose which classifier you\n",
    "         want to use:\n",
    "         Enter 1 for Naive-Bayes\n",
    "         Enter 2 for SVM\n",
    "         Enter 3 for Logistic Regression'''\n",
    "\n",
    "print(note)\n",
    "switch = int(input(\"Enter choice: \"))\n",
    "\n",
    "if switch == 1:\n",
    "    classifier(NB)\n",
    "elif switch == 2:\n",
    "    classifier(SVM)\n",
    "elif switch == 3:\n",
    "    classifier(LR)\n",
    "else:\n",
    "    print(\"wrong choice\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
